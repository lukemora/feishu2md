// Package main åŒ…å«å°†é£ä¹¦æ–‡æ¡£è½¬æ¢ä¸ºMarkdownçš„ä¸‹è½½åŠŸèƒ½
// æ­¤æ–‡ä»¶å¤„ç†æ ¸å¿ƒä¸‹è½½æ“ä½œï¼ŒåŒ…æ‹¬å•ä¸ªæ–‡æ¡£ã€æ‰¹é‡æ–‡ä»¶å¤¹å’ŒçŸ¥è¯†åº“
package main

import (
	"context"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"sync"

	"github.com/88250/lute"
	"github.com/Wsine/feishu2md/core"
	"github.com/Wsine/feishu2md/utils"
	"github.com/chyroc/lark"
	"github.com/pkg/errors"
	"github.com/urfave/cli/v2"
)

// DownloadOpts åŒ…å«ä¸‹è½½æ“ä½œçš„é€‰é¡¹
type DownloadOpts struct {
	outputDir    string // æ–‡ä»¶ä¿å­˜çš„ç›®å½•
	dump         bool   // æ˜¯å¦è½¬å‚¨APIçš„JSONå“åº”
	batch        bool   // æ˜¯å¦ä¸‹è½½æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡æ¡£
	wiki         bool   // æ˜¯å¦ä¸‹è½½çŸ¥è¯†åº“ä¸­çš„æ‰€æœ‰æ–‡æ¡£
	wikiChildren bool   // æ˜¯å¦ä¸‹è½½æŒ‡å®šçŸ¥è¯†åº“æ–‡æ¡£ä¸‹çš„æ‰€æœ‰å­æ–‡æ¡£
	spaceID      string // çŸ¥è¯†åº“ç©ºé—´IDï¼ˆç”¨äºæ£€æŸ¥å­èŠ‚ç‚¹ï¼‰
	nodeToken    string // å½“å‰èŠ‚ç‚¹ä»¤ç‰Œï¼ˆç”¨äºæ£€æŸ¥å­èŠ‚ç‚¹ï¼‰
}

// dlConfig ä¿å­˜å½“å‰ä¸‹è½½æ“ä½œçš„é…ç½®
var dlConfig core.Config

// downloadDocument ä¸‹è½½å•ä¸ªé£ä¹¦æ–‡æ¡£å¹¶è½¬æ¢ä¸ºMarkdown
// å®ƒå¤„ç†æ–‡æ¡£éªŒè¯ã€å†…å®¹æ£€ç´¢ã€å›¾ç‰‡å¤„ç†å’Œæ–‡ä»¶è¾“å‡º
func downloadDocument(ctx context.Context, client *core.Client, url string, opts *DownloadOpts) error {
	// éªŒè¯URLå¹¶æå–æ–‡æ¡£ç±»å‹å’Œä»¤ç‰Œ
	docType, docToken, err := utils.ValidateDocumentURL(url)
	if err != nil {
		return err
	}
	// ç§»é™¤å†—ä½™çš„ä»¤ç‰Œè¾“å‡º

	// å¯¹äºçŸ¥è¯†åº“é¡µé¢ï¼Œæˆ‘ä»¬éœ€è¦å…ˆæ›´æ–°docTypeå’ŒdocToken
	if docType == "wiki" {
		node, err := client.GetWikiNodeInfo(ctx, docToken)
		if err != nil {
			err = fmt.Errorf("GetWikiNodeInfo err: %v for %v", err, url)
		}
		utils.CheckErr(err)
		docType = node.ObjType
		docToken = node.ObjToken

		// å¦‚æœæä¾›äº†spaceIDï¼Œæ£€æŸ¥è¯¥èŠ‚ç‚¹æ˜¯å¦æœ‰å­èŠ‚ç‚¹
		if opts.spaceID != "" {
			childNodes, err := client.GetChildNodes(ctx, opts.spaceID, node.NodeToken)
			if err == nil && len(childNodes) > 0 {
				fmt.Printf("â­ï¸  è·³è¿‡æœ‰å­èŠ‚ç‚¹çš„æ–‡æ¡£: %s\n", node.Title)
				return nil
			}
		}
	}
	if docType == "docs" {
		return errors.Errorf(
			`ä¸å†æ”¯æŒé£ä¹¦æ–‡æ¡£ã€‚` +
				`è¯·å‚è€ƒReadme/Releaseè·å–v1_supportä¿¡æ¯ã€‚`)
	}

	// å¤„ç†ä¸‹è½½
	docx, blocks, err := client.GetDocxContent(ctx, docToken)
	utils.CheckErr(err)

	parser := core.NewParser(dlConfig.Output)

	title := docx.Title
	markdown := parser.ParseDocxContent(docx, blocks)

	if !dlConfig.Output.SkipImgDownload && len(parser.ImgTokens) > 0 {
		successCount := 0
		for _, imgToken := range parser.ImgTokens {
			localLink, err := client.DownloadImage(
				ctx, imgToken, filepath.Join(opts.outputDir, dlConfig.Output.ImageDir),
			)
			if err != nil {
				// å›¾ç‰‡ä¸‹è½½å¤±è´¥æ—¶ä¸åº”è¯¥å¯¼è‡´æ•´ä¸ªæ–‡æ¡£ä¸‹è½½å¤±è´¥
				// è®°å½•è­¦å‘Šå¹¶ç»§ç»­å¤„ç†å…¶ä»–å›¾ç‰‡
				fmt.Printf("âš ï¸  å›¾ç‰‡ä¸‹è½½å¤±è´¥: %v\n", err)
				continue
			}
			markdown = strings.Replace(markdown, imgToken, localLink, 1)
			successCount++
		}
		if successCount > 0 {
			fmt.Printf("ğŸ“¸ ä¸‹è½½äº† %d å¼ å›¾ç‰‡\n", successCount)
		}
	}

	// Format the markdown document
	engine := lute.New(func(l *lute.Lute) {
		l.RenderOptions.AutoSpace = true
	})
	result := engine.FormatStr("md", markdown)

	// å¤„ç†è¾“å‡ºç›®å½•å’Œåç§°
	if _, err := os.Stat(opts.outputDir); os.IsNotExist(err) {
		if err := os.MkdirAll(opts.outputDir, 0o755); err != nil {
			return err
		}
	}

	if opts.dump {
		jsonName := fmt.Sprintf("%s.json", docToken)
		outputPath := filepath.Join(opts.outputDir, jsonName)
		data := struct {
			Document *lark.DocxDocument `json:"document"`
			Blocks   []*lark.DocxBlock  `json:"blocks"`
		}{
			Document: docx,
			Blocks:   blocks,
		}
		pdata := utils.PrettyPrint(data)

		if err = os.WriteFile(outputPath, []byte(pdata), 0o644); err != nil {
			return err
		}
		fmt.Printf("ğŸ“„ JSONå“åº”å·²è½¬å‚¨åˆ° %s\n", outputPath)
	}

	// å†™å…¥markdownæ–‡ä»¶
	mdName := fmt.Sprintf("%s.md", docToken)
	if dlConfig.Output.TitleAsFilename {
		mdName = fmt.Sprintf("%s.md", utils.SanitizeFileName(title))
	}
	outputPath := filepath.Join(opts.outputDir, mdName)
	if err = os.WriteFile(outputPath, []byte(result), 0o644); err != nil {
		return err
	}
	fmt.Printf("âœ… %s\n", title)

	return nil
}

// downloadDocuments ä¸‹è½½æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡æ¡£
func downloadDocuments(ctx context.Context, client *core.Client, url string, opts *DownloadOpts) error {
	// éªŒè¯è¦ä¸‹è½½çš„URL
	folderToken, err := utils.ValidateFolderURL(url)
	if err != nil {
		return err
	}
	// ç§»é™¤å†—ä½™çš„ä»¤ç‰Œè¾“å‡º

	// é”™è¯¯é€šé“å’Œç­‰å¾…ç»„
	errChan := make(chan error)
	wg := sync.WaitGroup{}

	// é€’å½’éå†æ–‡ä»¶å¤¹å¹¶ä¸‹è½½æ–‡æ¡£
	var processFolder func(ctx context.Context, folderPath, folderToken string) error
	processFolder = func(ctx context.Context, folderPath, folderToken string) error {
		files, err := client.GetDriveFolderFileList(ctx, nil, &folderToken)
		if err != nil {
			return err
		}
		localOpts := DownloadOpts{
			outputDir: folderPath,
			dump:      opts.dump,
			batch:     false,
			spaceID:   opts.spaceID,
			nodeToken: opts.nodeToken,
		}
		for _, file := range files {
			if file.Type == "folder" {
				_folderPath := filepath.Join(folderPath, file.Name)
				if err := processFolder(ctx, _folderPath, file.Token); err != nil {
					return err
				}
			} else if file.Type == "docx" {
				// å¹¶å‘ä¸‹è½½æ–‡æ¡£
				wg.Add(1)
				go func(_url string) {
					if err := downloadDocument(ctx, client, _url, &localOpts); err != nil {
						errChan <- err
					}
					wg.Done()
				}(file.URL)
			}
		}
		return nil
	}
	if err := processFolder(ctx, opts.outputDir, folderToken); err != nil {
		return err
	}

	// Wait for all the downloads to finish
	go func() {
		wg.Wait()
		close(errChan)
	}()
	for err := range errChan {
		return err
	}
	return nil
}

// downloadWiki ä¸‹è½½çŸ¥è¯†åº“ä¸­çš„æ‰€æœ‰æ–‡æ¡£
func downloadWiki(ctx context.Context, client *core.Client, url string, opts *DownloadOpts) error {
	prefixURL, spaceID, err := utils.ValidateWikiURL(url)
	if err != nil {
		return err
	}

	folderPath, err := client.GetWikiName(ctx, spaceID)
	if err != nil {
		return err
	}
	if folderPath == "" {
		return fmt.Errorf("failed to GetWikiName")
	}

	errChan := make(chan error)

	var maxConcurrency = 10 // è®¾ç½®æœ€å¤§å¹¶å‘çº§åˆ«
	wg := sync.WaitGroup{}
	semaphore := make(chan struct{}, maxConcurrency) // åˆ›å»ºå…·æœ‰æœ€å¤§å¹¶å‘çº§åˆ«çš„ä¿¡å·é‡

	var downloadWikiNode func(ctx context.Context,
		client *core.Client,
		spaceID string,
		parentPath string,
		parentNodeToken *string) error

	downloadWikiNode = func(ctx context.Context,
		client *core.Client,
		spaceID string,
		folderPath string,
		parentNodeToken *string) error {
		nodes, err := client.GetWikiNodeList(ctx, spaceID, parentNodeToken)
		if err != nil {
			return err
		}
		for _, n := range nodes {
			if n.HasChild {
				_folderPath := filepath.Join(folderPath, n.Title)
				if err := downloadWikiNode(ctx, client,
					spaceID, _folderPath, &n.NodeToken); err != nil {
					return err
				}
			}
			if n.ObjType == "docx" {
				wikiOpts := DownloadOpts{
					outputDir: folderPath,
					dump:      opts.dump,
					batch:     false,
					spaceID:   spaceID,
					nodeToken: n.NodeToken,
				}
				wg.Add(1)
				semaphore <- struct{}{}
				go func(_url string) {
					if err := downloadDocument(ctx, client, _url, &wikiOpts); err != nil {
						errChan <- err
					}
					wg.Done()
					<-semaphore
				}(prefixURL + "/wiki/" + n.NodeToken)
			}
		}
		return nil
	}

	if err = downloadWikiNode(ctx, client, spaceID, folderPath, nil); err != nil {
		return err
	}

	// Wait for all the downloads to finish
	go func() {
		wg.Wait()
		close(errChan)
	}()
	for err := range errChan {
		return err
	}
	return nil
}

// downloadWikiChildren ä¸‹è½½æŒ‡å®šçŸ¥è¯†åº“æ–‡æ¡£ä¸‹çš„æ‰€æœ‰å­æ–‡æ¡£
func downloadWikiChildren(ctx context.Context, client *core.Client, url string, opts *DownloadOpts) error {
	// ä¼˜å…ˆä½¿ç”¨é…ç½®ä¸­çš„spaceIDï¼Œç„¶åä½¿ç”¨ç¯å¢ƒå˜é‡
	spaceID := opts.spaceID
	if spaceID == "" {
		spaceID = os.Getenv("FEISHU_SPACE_ID")
	}
	var prefixURL string

	if spaceID == "" {
		// å°è¯•ä»URLè§£æspaceIDï¼ˆå¦‚æœæ˜¯çŸ¥è¯†åº“è®¾ç½®é¡µé¢URLï¼‰
		var parsedSpaceID string
		var err error
		prefixURL, parsedSpaceID, err = utils.ValidateWikiURL(url)
		if err == nil {
			spaceID = parsedSpaceID
		}
	}

	if spaceID == "" {
		return fmt.Errorf("æ— æ³•è·å–çŸ¥è¯†åº“spaceIDã€‚è¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼æä¾›:\n" +
			"  1. å‘½ä»¤è¡Œå‚æ•°: --space-id <id>\n" +
			"  2. ç¯å¢ƒå˜é‡: FEISHU_SPACE_ID\n" +
			"  3. ä½¿ç”¨çŸ¥è¯†åº“è®¾ç½®é¡µé¢URL")
	}

	// å¦‚æœè¿˜æ²¡æœ‰è·å–URLå‰ç¼€ï¼Œåˆ™ä»URLä¸­æå–
	if prefixURL == "" {
		if urlParts := strings.Split(url, "/wiki/"); len(urlParts) >= 2 {
			prefixURL = urlParts[0]
		}
	}

	// ä»URLä¸­æå–nodeToken
	docType, nodeToken, err := utils.ValidateDocumentURL(url)
	if err != nil {
		return err
	}

	// å¦‚æœæ˜¯wikiç±»å‹ï¼Œéœ€è¦è·å–å®é™…çš„æ–‡æ¡£ä¿¡æ¯
	if docType == "wiki" {
		node, err := client.GetWikiNodeInfo(ctx, nodeToken)
		if err != nil {
			return fmt.Errorf("GetWikiNodeInfo err: %v for %v", err, url)
		}
		nodeToken = node.NodeToken
	}

	fmt.Printf("ğŸ” æ­£åœ¨è·å–å­æ–‡æ¡£...\n")

	// è·å–æ‰€æœ‰å­èŠ‚ç‚¹
	allNodes, err := client.GetAllChildNodes(ctx, spaceID, nodeToken)
	if err != nil {
		return fmt.Errorf("è·å–å­èŠ‚ç‚¹å¤±è´¥: %v", err)
	}

	if len(allNodes) == 0 {
		fmt.Println("ğŸ“­ æœªæ‰¾åˆ°ä»»ä½•å­æ–‡æ¡£")
		return nil
	}

	fmt.Printf("ğŸ“š æ‰¾åˆ° %d ä¸ªå­æ–‡æ¡£\n", len(allNodes))

	// åˆ›å»ºç›®å½•ç»“æ„æ˜ å°„ï¼šnodeToken -> ç›¸å¯¹è·¯å¾„
	pathMap := make(map[string]string)

	// é¦–å…ˆä¸ºæ ¹èŠ‚ç‚¹å»ºç«‹è·¯å¾„
	pathMap[nodeToken] = "."

	// é€’å½’æ„å»ºè·¯å¾„æ˜ å°„
	var buildPaths func(parentToken, parentPath string)
	buildPaths = func(parentToken, parentPath string) {
		for _, node := range allNodes {
			if node.ParentToken == parentToken {
				// æ„å»ºå½“å‰èŠ‚ç‚¹çš„è·¯å¾„
				nodePath := filepath.Join(parentPath, utils.SanitizeFileName(node.Name))
				pathMap[node.NodeToken] = nodePath

				// å¦‚æœæœ‰å­èŠ‚ç‚¹ï¼Œé€’å½’å¤„ç†
				if node.HasChild {
					buildPaths(node.NodeToken, nodePath)
				}
			}
		}
	}

	buildPaths(nodeToken, ".")

	// å¹¶å‘ä¸‹è½½æ§åˆ¶
	var maxConcurrency = 10
	errChan := make(chan error, len(allNodes))
	wg := sync.WaitGroup{}
	semaphore := make(chan struct{}, maxConcurrency)

	// ä¸‹è½½æ‰€æœ‰æ–‡æ¡£ç±»å‹çš„èŠ‚ç‚¹
	for _, node := range allNodes {
		if node.Type == "docx" {
			wg.Add(1)
			semaphore <- struct{}{}

			go func(n *core.Document) {
				defer func() {
					wg.Done()
					<-semaphore
				}()

				// ç¡®å®šæ–‡æ¡£çš„è¾“å‡ºç›®å½•
				nodePath := pathMap[n.ParentToken]
				if nodePath == "" {
					nodePath = "." // é»˜è®¤åˆ°å½“å‰ç›®å½•
				}

				fullOutputDir := filepath.Join(opts.outputDir, nodePath)

				// åˆ›å»ºè¾“å‡ºç›®å½•
				if err := os.MkdirAll(fullOutputDir, 0o755); err != nil {
					errChan <- fmt.Errorf("åˆ›å»ºç›®å½•å¤±è´¥ %s: %v", fullOutputDir, err)
					return
				}

				// æ„å»ºæ–‡æ¡£URLå¹¶ä¸‹è½½
				docURL := prefixURL + "/wiki/" + n.NodeToken
				localOpts := DownloadOpts{
					outputDir:    fullOutputDir,
					dump:         opts.dump,
					batch:        false,
					wiki:         false,
					wikiChildren: false,
					spaceID:      spaceID,
					nodeToken:    n.NodeToken,
				}

				// ç§»é™¤å†—ä½™çš„ä¸‹è½½è·¯å¾„è¾“å‡º
				if err := downloadDocument(ctx, client, docURL, &localOpts); err != nil {
					errChan <- fmt.Errorf("ä¸‹è½½æ–‡æ¡£å¤±è´¥ %s: %v", n.Name, err)
				}
			}(node)
		}
	}

	// ç­‰å¾…æ‰€æœ‰ä¸‹è½½å®Œæˆ
	go func() {
		wg.Wait()
		close(errChan)
	}()

	// æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
	for err := range errChan {
		if err != nil {
			return err
		}
	}

	fmt.Printf("ğŸ‰ å®Œæˆï¼æˆåŠŸä¸‹è½½äº† %d ä¸ªæ–‡æ¡£\n", len(allNodes))
	return nil
}

// handleDownloadCommand æ˜¯ä¸‹è½½æ“ä½œçš„ä¸»è¦å¤„ç†ç¨‹åº
// å®ƒå¤„ç†CLIæ ‡å¿—ã€åŠ è½½é…ç½®ã€éªŒè¯å‡­æ®å¹¶å¯åŠ¨é€‚å½“çš„ä¸‹è½½ç±»å‹
func handleDownloadCommand(cliCtx *cli.Context, url string) error {
	// æå–ä¸‹è½½é…ç½®çš„æ‰€æœ‰CLIæ ‡å¿—
	appId := cliCtx.String("app-id")
	appSecret := cliCtx.String("app-secret")
	spaceId := cliCtx.String("space-id")
	outputDir := cliCtx.String("output")
	dump := cliCtx.Bool("dump")
	batch := cliCtx.Bool("batch")
	wiki := cliCtx.Bool("wiki")
	wikiChildren := cliCtx.Bool("wiki-children")
	titleAsFilename := cliCtx.Bool("title-as-filename")
	imageDir := cliCtx.String("image-dir")
	useHTMLTags := cliCtx.Bool("use-html-tags")
	skipImgDownload := cliCtx.Bool("skip-img-download")

	// åŠ è½½é…ç½®ï¼Œä¼˜å…ˆçº§ï¼šCLIå‚æ•° > ç¯å¢ƒå˜é‡ > é»˜è®¤å€¼
	config, err := core.LoadConfig(appId, appSecret)
	if err != nil {
		return err
	}

	// éªŒè¯å‡­æ®
	if config.Feishu.AppId == "" || config.Feishu.AppSecret == "" {
		return cli.Exit("éœ€è¦åº”ç”¨IDå’Œåº”ç”¨å¯†é’¥ã€‚è¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¾ç½®:\n"+
			"  1. å‘½ä»¤è¡Œ: --app-id <id> --app-secret <secret>\n"+
			"  2. ç¯å¢ƒå˜é‡: FEISHU_APP_ID å’Œ FEISHU_APP_SECRET", 1)
	}

	// ä½¿ç”¨CLIæ ‡å¿—è¦†ç›–é…ç½®
	// titleAsFilename ç°åœ¨é»˜è®¤ä¸º trueï¼Œå¯ä»¥è¢«ç”¨æˆ·æ˜ç¡®è®¾ç½®ä¸º false
	config.Output.TitleAsFilename = titleAsFilename
	if useHTMLTags {
		config.Output.UseHTMLTags = true
	}
	if skipImgDownload {
		config.Output.SkipImgDownload = true
	}
	if imageDir != "img" { // ä»…åœ¨ç”¨æˆ·æä¾›éé»˜è®¤å€¼æ—¶è¦†ç›–
		config.Output.ImageDir = imageDir
	}

	dlConfig = *config

	// è®¾ç½®ä¸‹è½½é€‰é¡¹
	opts := DownloadOpts{
		outputDir:    outputDir,
		dump:         dump,
		batch:        batch,
		wiki:         wiki,
		wikiChildren: wikiChildren,
		spaceID:      spaceId, // ä½¿ç”¨CLIå‚æ•°æˆ–ç¯å¢ƒå˜é‡æä¾›çš„spaceID
		nodeToken:    "",      // å•ä¸ªæ–‡æ¡£ä¸‹è½½æ—¶é€šå¸¸ä¸éœ€è¦nodeToken
	}

	// å®ä¾‹åŒ–å®¢æˆ·ç«¯
	client := core.NewClient(
		config.Feishu.AppId, config.Feishu.AppSecret,
	)
	ctx := context.Background()

	if batch {
		return downloadDocuments(ctx, client, url, &opts)
	}

	if wiki {
		return downloadWiki(ctx, client, url, &opts)
	}

	if wikiChildren {
		return downloadWikiChildren(ctx, client, url, &opts)
	}

	return downloadDocument(ctx, client, url, &opts)
}
