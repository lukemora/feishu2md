// Package main åŒ…å«å°†é£ä¹¦æ–‡æ¡£è½¬æ¢ä¸ºMarkdownçš„ä¸‹è½½åŠŸèƒ½
// æ­¤æ–‡ä»¶å¤„ç†æ ¸å¿ƒä¸‹è½½æ“ä½œï¼ŒåŒ…æ‹¬å•ä¸ªæ–‡æ¡£ã€æ‰¹é‡æ–‡ä»¶å¤¹å’ŒçŸ¥è¯†åº“
package main

import (
	"context"
	"crypto/md5"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"strings"
	"sync"

	"github.com/88250/lute"
	"github.com/Wsine/feishu2md/core"
	"github.com/Wsine/feishu2md/utils"
	"github.com/chyroc/lark"
	"github.com/pkg/errors"
	"github.com/urfave/cli/v2"
)

// DownloadOpts åŒ…å«ä¸‹è½½æ“ä½œçš„é€‰é¡¹
type DownloadOpts struct {
	outputDir     string // æ–‡ä»¶ä¿å­˜çš„ç›®å½•
	dumpJSON      bool   // æ˜¯å¦è½¬å‚¨APIçš„JSONå“åº”
	skipDuplicate bool   // æ˜¯å¦è·³è¿‡é‡å¤æ–‡ä»¶
	forceDownload bool   // æ˜¯å¦å¼ºåˆ¶ä¸‹è½½
	spaceID       string // çŸ¥è¯†åº“ç©ºé—´IDï¼ˆç”¨äºæ£€æŸ¥å­èŠ‚ç‚¹ï¼‰
	nodeToken     string // å½“å‰èŠ‚ç‚¹ä»¤ç‰Œï¼ˆç”¨äºæ£€æŸ¥å­èŠ‚ç‚¹ï¼‰
}

// calculateMD5 è®¡ç®—å­—ç¬¦ä¸²çš„MD5å“ˆå¸Œå€¼
func calculateMD5(content string) string {
	h := md5.New()
	io.WriteString(h, content)
	return fmt.Sprintf("%x", h.Sum(nil))
}

// fileExists æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
func fileExists(filepath string) bool {
	_, err := os.Stat(filepath)
	return !os.IsNotExist(err)
}

// shouldSkipFile æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡æ–‡ä»¶ä¸‹è½½ï¼ˆåŸºäºå†…å®¹å¯¹æ¯”ï¼‰
func shouldSkipFile(outputPath, content string, skipDuplicate bool) bool {
	if !skipDuplicate {
		return false
	}

	if !fileExists(outputPath) {
		return false
	}

	// è¯»å–ç°æœ‰æ–‡ä»¶å†…å®¹
	existingContent, err := os.ReadFile(outputPath)
	if err != nil {
		// è¯»å–å¤±è´¥ï¼Œä¸è·³è¿‡
		return false
	}

	// å¯¹æ¯”MD5å“ˆå¸Œå€¼
	existingMD5 := calculateMD5(string(existingContent))
	newMD5 := calculateMD5(content)

	return existingMD5 == newMD5
}

// dlConfig ä¿å­˜å½“å‰ä¸‹è½½æ“ä½œçš„é…ç½®
var dlConfig core.Config

// downloadDocument ä¸‹è½½å•ä¸ªé£ä¹¦æ–‡æ¡£å¹¶è½¬æ¢ä¸ºMarkdown
// å®ƒå¤„ç†æ–‡æ¡£éªŒè¯ã€å†…å®¹æ£€ç´¢ã€å›¾ç‰‡å¤„ç†å’Œæ–‡ä»¶è¾“å‡º
func downloadDocument(ctx context.Context, client *core.Client, url string, opts *DownloadOpts) error {
	// éªŒè¯URLå¹¶æå–æ–‡æ¡£ç±»å‹å’Œä»¤ç‰Œ
	docType, docToken, err := utils.ValidateDocumentURL(url)
	if err != nil {
		return err
	}
	// ç§»é™¤å†—ä½™çš„ä»¤ç‰Œè¾“å‡º

	// å¯¹äºçŸ¥è¯†åº“é¡µé¢ï¼Œæˆ‘ä»¬éœ€è¦å…ˆæ›´æ–°docTypeå’ŒdocToken
	if docType == "wiki" {
		node, err := client.GetWikiNodeInfo(ctx, docToken)
		if err != nil {
			err = fmt.Errorf("GetWikiNodeInfo err: %v for %v", err, url)
		}
		utils.CheckErr(err)
		docType = node.ObjType
		docToken = node.ObjToken

		// å¦‚æœæä¾›äº†spaceIDï¼Œæ£€æŸ¥è¯¥èŠ‚ç‚¹æ˜¯å¦æœ‰å­èŠ‚ç‚¹
		if opts.spaceID != "" {
			childNodes, err := client.GetChildNodes(ctx, opts.spaceID, node.NodeToken)
			if err == nil && len(childNodes) > 0 {
				fmt.Printf("â­ï¸  è·³è¿‡æœ‰å­èŠ‚ç‚¹çš„æ–‡æ¡£: %s\n", node.Title)
				return nil
			}
		}
	}
	if docType == "docs" {
		return errors.Errorf(
			`ä¸å†æ”¯æŒé£ä¹¦æ–‡æ¡£ã€‚` +
				`è¯·å‚è€ƒReadme/Releaseè·å–v1_supportä¿¡æ¯ã€‚`)
	}

	// å¤„ç†ä¸‹è½½
	docx, blocks, err := client.GetDocxContent(ctx, docToken)
	utils.CheckErr(err)

	parser := core.NewParser(dlConfig.Output)

	title := docx.Title
	markdown := parser.ParseDocxContent(docx, blocks)

	if !dlConfig.Output.SkipImgDownload && len(parser.ImgTokens) > 0 {
		successCount := 0
		for _, imgToken := range parser.ImgTokens {
			localLink, err := client.DownloadImage(
				ctx, imgToken, filepath.Join(opts.outputDir, dlConfig.Output.ImageDir),
			)
			if err != nil {
				// å›¾ç‰‡ä¸‹è½½å¤±è´¥æ—¶ä¸åº”è¯¥å¯¼è‡´æ•´ä¸ªæ–‡æ¡£ä¸‹è½½å¤±è´¥
				// è®°å½•è­¦å‘Šå¹¶ç»§ç»­å¤„ç†å…¶ä»–å›¾ç‰‡
				fmt.Printf("âš ï¸  å›¾ç‰‡ä¸‹è½½å¤±è´¥: %v\n", err)
				continue
			}
			markdown = strings.Replace(markdown, imgToken, localLink, 1)
			successCount++
		}
		if successCount > 0 {
			fmt.Printf("ğŸ“¸ ä¸‹è½½äº† %d å¼ å›¾ç‰‡\n", successCount)
		}
	}

	// Format the markdown document
	engine := lute.New(func(l *lute.Lute) {
		l.RenderOptions.AutoSpace = true
	})
	result := engine.FormatStr("md", markdown)

	// å¤„ç†è¾“å‡ºç›®å½•å’Œåç§°
	if _, err := os.Stat(opts.outputDir); os.IsNotExist(err) {
		if err := os.MkdirAll(opts.outputDir, 0o755); err != nil {
			return err
		}
	}

	if opts.dumpJSON {
		jsonName := fmt.Sprintf("%s.json", docToken)
		jsonOutputPath := filepath.Join(opts.outputDir, jsonName)
		data := struct {
			Document *lark.DocxDocument `json:"document"`
			Blocks   []*lark.DocxBlock  `json:"blocks"`
		}{
			Document: docx,
			Blocks:   blocks,
		}
		pdata := utils.PrettyPrint(data)

		// æ£€æŸ¥JSONæ–‡ä»¶æ˜¯å¦éœ€è¦è·³è¿‡
		if !opts.forceDownload && shouldSkipFile(jsonOutputPath, pdata, opts.skipDuplicate) {
			fmt.Printf("â­ï¸  è·³è¿‡é‡å¤JSON: %s\n", jsonName)
		} else {
			if err = os.WriteFile(jsonOutputPath, []byte(pdata), 0o644); err != nil {
				return err
			}
			fmt.Printf("ğŸ“„ JSONå“åº”å·²è½¬å‚¨åˆ° %s\n", jsonOutputPath)
		}
	}

	// å†™å…¥markdownæ–‡ä»¶
	mdName := fmt.Sprintf("%s.md", docToken)
	if dlConfig.Output.TitleAsFilename {
		mdName = fmt.Sprintf("%s.md", utils.SanitizeFileName(title))
	}
	outputPath := filepath.Join(opts.outputDir, mdName)

	// æ£€æŸ¥æ˜¯å¦éœ€è¦è·³è¿‡é‡å¤æ–‡ä»¶
	if !opts.forceDownload && shouldSkipFile(outputPath, result, opts.skipDuplicate) {
		fmt.Printf("â­ï¸  è·³è¿‡é‡å¤æ–‡ä»¶: %s\n", title)
		return nil
	}

	if err = os.WriteFile(outputPath, []byte(result), 0o644); err != nil {
		return err
	}
	fmt.Printf("âœ… %s\n", title)

	return nil
}

// downloadDocuments ä¸‹è½½æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡æ¡£
func downloadDocuments(ctx context.Context, client *core.Client, url string, opts *DownloadOpts) error {
	// éªŒè¯è¦ä¸‹è½½çš„URL
	folderToken, err := utils.ValidateFolderURL(url)
	if err != nil {
		return err
	}
	// ç§»é™¤å†—ä½™çš„ä»¤ç‰Œè¾“å‡º

	// é”™è¯¯é€šé“å’Œç­‰å¾…ç»„
	errChan := make(chan error)
	wg := sync.WaitGroup{}

	// é€’å½’éå†æ–‡ä»¶å¤¹å¹¶ä¸‹è½½æ–‡æ¡£
	var processFolder func(ctx context.Context, folderPath, folderToken string) error
	processFolder = func(ctx context.Context, folderPath, folderToken string) error {
		files, err := client.GetDriveFolderFileList(ctx, nil, &folderToken)
		if err != nil {
			return err
		}
		localOpts := DownloadOpts{
			outputDir:     folderPath,
			dumpJSON:      opts.dumpJSON,
			skipDuplicate: opts.skipDuplicate,
			forceDownload: opts.forceDownload,
			spaceID:       opts.spaceID,
			nodeToken:     opts.nodeToken,
		}
		for _, file := range files {
			if file.Type == "folder" {
				_folderPath := filepath.Join(folderPath, file.Name)
				if err := processFolder(ctx, _folderPath, file.Token); err != nil {
					return err
				}
			} else if file.Type == "docx" {
				// å¹¶å‘ä¸‹è½½æ–‡æ¡£
				wg.Add(1)
				go func(_url string) {
					if err := downloadDocument(ctx, client, _url, &localOpts); err != nil {
						errChan <- err
					}
					wg.Done()
				}(file.URL)
			}
		}
		return nil
	}
	if err := processFolder(ctx, opts.outputDir, folderToken); err != nil {
		return err
	}

	// Wait for all the downloads to finish
	go func() {
		wg.Wait()
		close(errChan)
	}()
	for err := range errChan {
		return err
	}
	return nil
}

// downloadWiki ä¸‹è½½çŸ¥è¯†åº“ä¸­çš„æ‰€æœ‰æ–‡æ¡£
func downloadWiki(ctx context.Context, client *core.Client, url string, opts *DownloadOpts) error {
	prefixURL, spaceID, err := utils.ValidateWikiURL(url)
	if err != nil {
		return err
	}

	folderPath, err := client.GetWikiName(ctx, spaceID)
	if err != nil {
		return err
	}
	if folderPath == "" {
		return fmt.Errorf("failed to GetWikiName")
	}

	errChan := make(chan error)

	var maxConcurrency = 10 // è®¾ç½®æœ€å¤§å¹¶å‘çº§åˆ«
	wg := sync.WaitGroup{}
	semaphore := make(chan struct{}, maxConcurrency) // åˆ›å»ºå…·æœ‰æœ€å¤§å¹¶å‘çº§åˆ«çš„ä¿¡å·é‡

	var downloadWikiNode func(ctx context.Context,
		client *core.Client,
		spaceID string,
		parentPath string,
		parentNodeToken *string) error

	downloadWikiNode = func(ctx context.Context,
		client *core.Client,
		spaceID string,
		folderPath string,
		parentNodeToken *string) error {
		nodes, err := client.GetWikiNodeList(ctx, spaceID, parentNodeToken)
		if err != nil {
			return err
		}
		for _, n := range nodes {
			if n.HasChild {
				_folderPath := filepath.Join(folderPath, n.Title)
				if err := downloadWikiNode(ctx, client,
					spaceID, _folderPath, &n.NodeToken); err != nil {
					return err
				}
			}
			if n.ObjType == "docx" {
				wikiOpts := DownloadOpts{
					outputDir:     folderPath,
					dumpJSON:      opts.dumpJSON,
					skipDuplicate: opts.skipDuplicate,
					forceDownload: opts.forceDownload,
					spaceID:       spaceID,
					nodeToken:     n.NodeToken,
				}
				wg.Add(1)
				semaphore <- struct{}{}
				go func(_url string) {
					if err := downloadDocument(ctx, client, _url, &wikiOpts); err != nil {
						errChan <- err
					}
					wg.Done()
					<-semaphore
				}(prefixURL + "/wiki/" + n.NodeToken)
			}
		}
		return nil
	}

	if err = downloadWikiNode(ctx, client, spaceID, folderPath, nil); err != nil {
		return err
	}

	// Wait for all the downloads to finish
	go func() {
		wg.Wait()
		close(errChan)
	}()
	for err := range errChan {
		return err
	}
	return nil
}

// downloadWikiChildren ä¸‹è½½æŒ‡å®šçŸ¥è¯†åº“æ–‡æ¡£ä¸‹çš„æ‰€æœ‰å­æ–‡æ¡£
func downloadWikiChildren(ctx context.Context, client *core.Client, url string, opts *DownloadOpts) error {
	// ä¼˜å…ˆä½¿ç”¨é…ç½®ä¸­çš„spaceIDï¼Œç„¶åä½¿ç”¨ç¯å¢ƒå˜é‡
	spaceID := opts.spaceID
	if spaceID == "" {
		spaceID = os.Getenv("FEISHU_SPACE_ID")
	}
	var prefixURL string

	if spaceID == "" {
		// å°è¯•ä»URLè§£æspaceIDï¼ˆå¦‚æœæ˜¯çŸ¥è¯†åº“è®¾ç½®é¡µé¢URLï¼‰
		var parsedSpaceID string
		var err error
		prefixURL, parsedSpaceID, err = utils.ValidateWikiURL(url)
		if err == nil {
			spaceID = parsedSpaceID
		}
	}

	if spaceID == "" {
		return fmt.Errorf("æ— æ³•è·å–çŸ¥è¯†åº“spaceIDã€‚è¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼æä¾›:\n" +
			"  1. å‘½ä»¤è¡Œå‚æ•°: --space-id <id>\n" +
			"  2. ç¯å¢ƒå˜é‡: FEISHU_SPACE_ID\n" +
			"  3. ä½¿ç”¨çŸ¥è¯†åº“è®¾ç½®é¡µé¢URL")
	}

	// å¦‚æœè¿˜æ²¡æœ‰è·å–URLå‰ç¼€ï¼Œåˆ™ä»URLä¸­æå–
	if prefixURL == "" {
		if urlParts := strings.Split(url, "/wiki/"); len(urlParts) >= 2 {
			prefixURL = urlParts[0]
		}
	}

	// ä»URLä¸­æå–nodeToken
	docType, nodeToken, err := utils.ValidateDocumentURL(url)
	if err != nil {
		return err
	}

	// å¦‚æœæ˜¯wikiç±»å‹ï¼Œéœ€è¦è·å–å®é™…çš„æ–‡æ¡£ä¿¡æ¯
	if docType == "wiki" {
		node, err := client.GetWikiNodeInfo(ctx, nodeToken)
		if err != nil {
			return fmt.Errorf("GetWikiNodeInfo err: %v for %v", err, url)
		}
		nodeToken = node.NodeToken
	}

	fmt.Printf("ğŸ” æ­£åœ¨è·å–å­æ–‡æ¡£...\n")

	// è·å–æ‰€æœ‰å­èŠ‚ç‚¹
	allNodes, err := client.GetAllChildNodes(ctx, spaceID, nodeToken)
	if err != nil {
		return fmt.Errorf("è·å–å­èŠ‚ç‚¹å¤±è´¥: %v", err)
	}

	if len(allNodes) == 0 {
		fmt.Println("ğŸ“­ æœªæ‰¾åˆ°ä»»ä½•å­æ–‡æ¡£")
		return nil
	}

	fmt.Printf("ğŸ“š æ‰¾åˆ° %d ä¸ªå­æ–‡æ¡£\n", len(allNodes))

	// åˆ›å»ºç›®å½•ç»“æ„æ˜ å°„ï¼šnodeToken -> ç›¸å¯¹è·¯å¾„
	pathMap := make(map[string]string)

	// é¦–å…ˆä¸ºæ ¹èŠ‚ç‚¹å»ºç«‹è·¯å¾„
	pathMap[nodeToken] = "."

	// é€’å½’æ„å»ºè·¯å¾„æ˜ å°„
	var buildPaths func(parentToken, parentPath string)
	buildPaths = func(parentToken, parentPath string) {
		for _, node := range allNodes {
			if node.ParentToken == parentToken {
				// æ„å»ºå½“å‰èŠ‚ç‚¹çš„è·¯å¾„
				nodePath := filepath.Join(parentPath, utils.SanitizeFileName(node.Name))
				pathMap[node.NodeToken] = nodePath

				// å¦‚æœæœ‰å­èŠ‚ç‚¹ï¼Œé€’å½’å¤„ç†
				if node.HasChild {
					buildPaths(node.NodeToken, nodePath)
				}
			}
		}
	}

	buildPaths(nodeToken, ".")

	// å¹¶å‘ä¸‹è½½æ§åˆ¶
	var maxConcurrency = 10
	errChan := make(chan error, len(allNodes))
	wg := sync.WaitGroup{}
	semaphore := make(chan struct{}, maxConcurrency)

	// ä¸‹è½½æ‰€æœ‰æ–‡æ¡£ç±»å‹çš„èŠ‚ç‚¹
	for _, node := range allNodes {
		if node.Type == "docx" {
			wg.Add(1)
			semaphore <- struct{}{}

			go func(n *core.Document) {
				defer func() {
					wg.Done()
					<-semaphore
				}()

				// ç¡®å®šæ–‡æ¡£çš„è¾“å‡ºç›®å½•
				nodePath := pathMap[n.ParentToken]
				if nodePath == "" {
					nodePath = "." // é»˜è®¤åˆ°å½“å‰ç›®å½•
				}

				fullOutputDir := filepath.Join(opts.outputDir, nodePath)

				// åˆ›å»ºè¾“å‡ºç›®å½•
				if err := os.MkdirAll(fullOutputDir, 0o755); err != nil {
					errChan <- fmt.Errorf("åˆ›å»ºç›®å½•å¤±è´¥ %s: %v", fullOutputDir, err)
					return
				}

				// æ„å»ºæ–‡æ¡£URLå¹¶ä¸‹è½½
				docURL := prefixURL + "/wiki/" + n.NodeToken
				localOpts := DownloadOpts{
					outputDir:     fullOutputDir,
					dumpJSON:      opts.dumpJSON,
					skipDuplicate: opts.skipDuplicate,
					forceDownload: opts.forceDownload,
					spaceID:       spaceID,
					nodeToken:     n.NodeToken,
				}

				// ç§»é™¤å†—ä½™çš„ä¸‹è½½è·¯å¾„è¾“å‡º
				if err := downloadDocument(ctx, client, docURL, &localOpts); err != nil {
					errChan <- fmt.Errorf("ä¸‹è½½æ–‡æ¡£å¤±è´¥ %s: %v", n.Name, err)
				}
			}(node)
		}
	}

	// ç­‰å¾…æ‰€æœ‰ä¸‹è½½å®Œæˆ
	go func() {
		wg.Wait()
		close(errChan)
	}()

	// æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
	for err := range errChan {
		if err != nil {
			return err
		}
	}

	fmt.Printf("ğŸ‰ å®Œæˆï¼æˆåŠŸä¸‹è½½äº† %d ä¸ªæ–‡æ¡£\n", len(allNodes))
	return nil
}

// createCommonOpts ä»CLIä¸Šä¸‹æ–‡åˆ›å»ºé€šç”¨çš„ä¸‹è½½é€‰é¡¹
func createCommonOpts(cliCtx *cli.Context) (*DownloadOpts, *core.Config, error) {
	// æå–CLIæ ‡å¿—
	appId := cliCtx.String("app-id")
	appSecret := cliCtx.String("app-secret")
	spaceId := cliCtx.String("space")
	outputDir := cliCtx.String("out")
	titleAsFilename := cliCtx.Bool("title-name")
	imageDir := cliCtx.String("img-dir")
	useHTML := cliCtx.Bool("html")
	skipImages := cliCtx.Bool("no-img")
	skipDuplicate := cliCtx.Bool("skip-same")
	forceDownload := cliCtx.Bool("force")
	dumpJSON := cliCtx.Bool("json")

	// åŠ è½½é…ç½®
	config, err := core.LoadConfig(appId, appSecret)
	if err != nil {
		return nil, nil, err
	}

	// éªŒè¯å‡­æ®
	if config.Feishu.AppId == "" || config.Feishu.AppSecret == "" {
		return nil, nil, cli.Exit("éœ€è¦åº”ç”¨IDå’Œåº”ç”¨å¯†é’¥ã€‚è¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¾ç½®:\n"+
			"  1. å‘½ä»¤è¡Œ: --app-id <id> --app-secret <secret>\n"+
			"  2. ç¯å¢ƒå˜é‡: FEISHU_APP_ID å’Œ FEISHU_APP_SECRET", 1)
	}

	// ä½¿ç”¨CLIæ ‡å¿—è¦†ç›–é…ç½®
	config.Output.TitleAsFilename = titleAsFilename
	config.Output.UseHTMLTags = useHTML
	config.Output.SkipImgDownload = skipImages
	if imageDir != "img" {
		config.Output.ImageDir = imageDir
	}

	// åˆ›å»ºä¸‹è½½é€‰é¡¹
	opts := &DownloadOpts{
		outputDir:     outputDir,
		dumpJSON:      dumpJSON,
		skipDuplicate: skipDuplicate,
		forceDownload: forceDownload,
		spaceID:       spaceId,
		nodeToken:     "",
	}

	return opts, config, nil
}

// handleDocumentDownload å¤„ç†å•ä¸ªæ–‡æ¡£ä¸‹è½½
func handleDocumentDownload(cliCtx *cli.Context, url string) error {
	opts, config, err := createCommonOpts(cliCtx)
	if err != nil {
		return err
	}

	dlConfig = *config
	client := core.NewClient(config.Feishu.AppId, config.Feishu.AppSecret)
	ctx := context.Background()

	return downloadDocument(ctx, client, url, opts)
}

// handleFolderDownload å¤„ç†æ–‡ä»¶å¤¹æ‰¹é‡ä¸‹è½½
func handleFolderDownload(cliCtx *cli.Context, url string) error {
	opts, config, err := createCommonOpts(cliCtx)
	if err != nil {
		return err
	}

	dlConfig = *config
	client := core.NewClient(config.Feishu.AppId, config.Feishu.AppSecret)
	ctx := context.Background()

	return downloadDocuments(ctx, client, url, opts)
}

// handleWikiDownload å¤„ç†çŸ¥è¯†åº“å®Œæ•´ä¸‹è½½
func handleWikiDownload(cliCtx *cli.Context, url string) error {
	opts, config, err := createCommonOpts(cliCtx)
	if err != nil {
		return err
	}

	dlConfig = *config
	client := core.NewClient(config.Feishu.AppId, config.Feishu.AppSecret)
	ctx := context.Background()

	return downloadWiki(ctx, client, url, opts)
}

// handleWikiTreeDownload å¤„ç†çŸ¥è¯†åº“å­æ–‡æ¡£ä¸‹è½½
func handleWikiTreeDownload(cliCtx *cli.Context, url string) error {
	opts, config, err := createCommonOpts(cliCtx)
	if err != nil {
		return err
	}

	dlConfig = *config
	client := core.NewClient(config.Feishu.AppId, config.Feishu.AppSecret)
	ctx := context.Background()

	return downloadWikiChildren(ctx, client, url, opts)
}

// handleLegacyDownload å¤„ç†é—ç•™çš„æ™ºèƒ½ä¸‹è½½å‘½ä»¤ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
func handleLegacyDownload(cliCtx *cli.Context, url string) error {
	fmt.Println("âš ï¸  ä½¿ç”¨äº†å·²åºŸå¼ƒçš„å‘½ä»¤ï¼Œå»ºè®®ä½¿ç”¨å…·ä½“çš„å­å‘½ä»¤:")
	fmt.Println("  - feishu2md document <url>  # ä¸‹è½½å•ä¸ªæ–‡æ¡£")
	fmt.Println("  - feishu2md folder <url>    # ä¸‹è½½æ–‡ä»¶å¤¹")
	fmt.Println("  - feishu2md wiki <url>      # ä¸‹è½½çŸ¥è¯†åº“")
	fmt.Println("  - feishu2md wiki-tree <url> # ä¸‹è½½å­æ–‡æ¡£")
	fmt.Println()

	// è‡ªåŠ¨æ£€æµ‹URLç±»å‹å¹¶ä½¿ç”¨ç›¸åº”çš„å¤„ç†å‡½æ•°
	if strings.Contains(url, "/drive/folder/") {
		return handleFolderDownload(cliCtx, url)
	}
	if strings.Contains(url, "/wiki/space/") {
		return handleWikiDownload(cliCtx, url)
	}
	if strings.Contains(url, "/wiki/") {
		// éœ€è¦æ£€æŸ¥æ˜¯å¦æœ‰spaceæ¥å†³å®šæ˜¯wiki-treeè¿˜æ˜¯å•æ–‡æ¡£
		if cliCtx.String("space") != "" {
			return handleWikiTreeDownload(cliCtx, url)
		}
	}

	// é»˜è®¤ä½œä¸ºå•æ–‡æ¡£å¤„ç†
	return handleDocumentDownload(cliCtx, url)
}

// handleDownloadCommand æ˜¯é—ç•™çš„ä¸»è¦å¤„ç†ç¨‹åºï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
func handleDownloadCommand(cliCtx *cli.Context, url string) error {
	return handleLegacyDownload(cliCtx, url)
}
