// Package main åŒ…å«å°†é£ä¹¦æ–‡æ¡£è½¬æ¢ä¸ºMarkdownçš„ä¸‹è½½åŠŸèƒ½
// æ­¤æ–‡ä»¶å¤„ç†æ ¸å¿ƒä¸‹è½½æ“ä½œï¼ŒåŒ…æ‹¬å•ä¸ªæ–‡æ¡£ã€æ‰¹é‡æ–‡ä»¶å¤¹å’ŒçŸ¥è¯†åº“
package main

import (
	"context"
	"crypto/md5"
	"fmt"
	"io"
	"os"
	"path/filepath"
	"sort"
	"strings"
	"sync"
	"time"

	"github.com/88250/lute"
	"github.com/Perfecto23/feishu2md/core"
	"github.com/Perfecto23/feishu2md/picgo"
	"github.com/Perfecto23/feishu2md/utils"
	"github.com/chyroc/lark"
	"github.com/pkg/errors"
	"github.com/urfave/cli/v2"
)

// DownloadOpts åŒ…å«ä¸‹è½½æ“ä½œçš„é€‰é¡¹
type DownloadOpts struct {
	outputDir     string   // æ–‡ä»¶ä¿å­˜çš„ç›®å½•
	dumpJSON      bool     // æ˜¯å¦è½¬å‚¨APIçš„JSONå“åº”
	skipDuplicate bool     // æ˜¯å¦è·³è¿‡é‡å¤æ–‡ä»¶
	forceDownload bool     // æ˜¯å¦å¼ºåˆ¶ä¸‹è½½
	spaceID       string   // çŸ¥è¯†åº“ç©ºé—´IDï¼ˆç”¨äºæ£€æŸ¥å­èŠ‚ç‚¹ï¼‰
	nodeToken     string   // å½“å‰èŠ‚ç‚¹ä»¤ç‰Œï¼ˆç”¨äºæ£€æŸ¥å­èŠ‚ç‚¹ï¼‰
	relDir        string   // ç›¸å¯¹æ ¹è¾“å‡ºç›®å½•çš„è·¯å¾„ï¼ˆä»… wiki-tree ç”¨äºæ—¥å¿—æ’åºï¼‰
	tags          []string // æ ‡ç­¾åˆ—è¡¨ï¼ˆä»è·¯å¾„æ‰€æœ‰å±‚çº§æ¨å¯¼ï¼‰
	category      string   // åˆ†ç±»ï¼ˆå•ä¸ªï¼Œä»è·¯å¾„æŒ‡å®šå±‚çº§æ¨å¯¼ï¼‰
	categoryLevel int      // åˆ†ç±»å±‚çº§: æ­£æ•°ä»å¤–å‘å†…(1=ç¬¬ä¸€å±‚), è´Ÿæ•°ä»å†…å‘å¤–(-1=æœ€åä¸€å±‚)
	cleanOutput   bool     // wiki-treeï¼šåŒæ­¥å‰æ¸…ç©ºè¾“å‡ºç›®å½•ï¼Œå†æŒ‰æœ€æ–°æ ‘ç”Ÿæˆï¼Œé¿å…æ—§æ–‡ä»¶æ®‹ç•™
}

// calculateMD5 è®¡ç®—å­—ç¬¦ä¸²çš„MD5å“ˆå¸Œå€¼
func calculateMD5(content string) string {
	h := md5.New()
	io.WriteString(h, content)
	return fmt.Sprintf("%x", h.Sum(nil))
}

// fileExists æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
func fileExists(filepath string) bool {
	_, err := os.Stat(filepath)
	return !os.IsNotExist(err)
}

// shouldSkipFile æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡æ–‡ä»¶ä¸‹è½½ï¼ˆåŸºäºå†…å®¹å¯¹æ¯”ï¼‰
func shouldSkipFile(outputPath, content string, skipDuplicate bool) bool {
	if !skipDuplicate {
		return false
	}

	if !fileExists(outputPath) {
		return false
	}

	// è¯»å–ç°æœ‰æ–‡ä»¶å†…å®¹
	existingContent, err := os.ReadFile(outputPath)
	if err != nil {
		// è¯»å–å¤±è´¥ï¼Œä¸è·³è¿‡
		return false
	}

	// å¯¹æ¯”MD5å“ˆå¸Œå€¼
	existingMD5 := calculateMD5(string(existingContent))
	newMD5 := calculateMD5(content)

	return existingMD5 == newMD5
}

// dlConfig ä¿å­˜å½“å‰ä¸‹è½½æ“ä½œçš„é…ç½®
var dlConfig core.Config

// DownloadStats ç”¨äºè·¨æ–‡æ¡£ç»Ÿè®¡ä¸‹è½½/ç¼“å­˜å‘½ä¸­ç­‰ä¿¡æ¯ï¼ˆä¸»è¦ç”¨äº wiki-tree æ±‡æ€»ï¼‰
type DownloadStats struct {
	mu          sync.Mutex
	totalDocs   int
	docsNew     int
	totalImages int
	imagesNew   int
}

func (s *DownloadStats) SetTotalDocs(n int) {
	s.mu.Lock()
	s.totalDocs = n
	s.mu.Unlock()
}
func (s *DownloadStats) AddDocNew() {
	s.mu.Lock()
	s.docsNew++
	s.mu.Unlock()
}
func (s *DownloadStats) AddImages(encountered, newlyDownloaded int) {
	s.mu.Lock()
	s.totalImages += encountered
	s.imagesNew += newlyDownloaded
	s.mu.Unlock()
}
func (s *DownloadStats) Snapshot() (totalDocs, docsNew, totalImages, imagesNew int) {
	s.mu.Lock()
	defer s.mu.Unlock()
	return s.totalDocs, s.docsNew, s.totalImages, s.imagesNew
}

// dlStats åœ¨ wiki-tree æ¨¡å¼ä¸‹åˆå§‹åŒ–ç”¨äºç»Ÿè®¡ï¼›å…¶ä»–æ¨¡å¼ä¿æŒ nil
var dlStats *DownloadStats

// DocLog è®°å½•å•ç¯‡æ–‡æ¡£çš„å¤„ç†æƒ…å†µ
type DocLog struct {
	Path     string
	Skipped  bool
	Reason   string
	ImgCache int
	ImgNew   int
	DocNew   bool // ä»…å½“é¦–æ¬¡åˆ›å»ºæ–‡ä»¶æ—¶è®°ä¸º true
}

type LogCollector struct {
	mu   sync.Mutex
	logs []DocLog
}

func (lc *LogCollector) Add(l DocLog) {
	lc.mu.Lock()
	lc.logs = append(lc.logs, l)
	lc.mu.Unlock()
}

func (lc *LogCollector) SortedByPath() []DocLog {
	lc.mu.Lock()
	defer lc.mu.Unlock()
	out := make([]DocLog, len(lc.logs))
	copy(out, lc.logs)
	// ç®€å•æŒ‰ Path å­—å…¸åºæ’åºï¼Œæ¥è¿‘æ–‡æ¡£å±‚çº§é¡ºåº
	sort.Slice(out, func(i, j int) bool { return out[i].Path < out[j].Path })
	return out
}

var logCollector = &LogCollector{}

// deriveTagsFromPath æ ¹æ® tagMode ä»ç›¸å¯¹è·¯å¾„æ¨å¯¼æ ‡ç­¾
// tagMode="last": åªå–æœ€åä¸€å±‚ç›®å½•ä½œä¸º tagï¼ˆé»˜è®¤è¡Œä¸ºï¼‰
// tagMode="all": å–è·¯å¾„çš„æ‰€æœ‰å±‚çº§ç›®å½•ä½œä¸º tags
// deriveTagsFromPath ä»ç›¸å¯¹è·¯å¾„æ¨å¯¼æ ‡ç­¾ï¼ˆå–æ‰€æœ‰å±‚çº§ç›®å½•ï¼‰
func deriveTagsFromPath(relPath string) []string {
	cleanPath := filepath.Clean(relPath)
	if cleanPath == "." || cleanPath == string(os.PathSeparator) || cleanPath == "" {
		return nil
	}

	// å–æ‰€æœ‰å±‚çº§ç›®å½•ä½œä¸º tags
	parts := strings.Split(cleanPath, string(os.PathSeparator))
	var tags []string
	for _, part := range parts {
		if part != "" && part != "." {
			tags = append(tags, part)
		}
	}
	return tags
}

// deriveCategoryFromPath æ ¹æ® level ä»ç›¸å¯¹è·¯å¾„æ¨å¯¼åˆ†ç±»
// level > 0: ä»å¤–å‘å†…æ•°ï¼ˆ1=ç¬¬ä¸€å±‚ï¼‰
// level < 0: ä»å†…å‘å¤–æ•°ï¼ˆ-1=æœ€åä¸€å±‚ï¼‰
// level = 0 æˆ–å±‚çº§ä¸å¤Ÿæ—¶è¿”å›ç©ºå­—ç¬¦ä¸²
func deriveCategoryFromPath(relPath string, level int) string {
	cleanPath := filepath.Clean(relPath)
	if cleanPath == "." || cleanPath == string(os.PathSeparator) || cleanPath == "" {
		return ""
	}

	// åˆ†å‰²è·¯å¾„è·å–æ‰€æœ‰å±‚çº§
	parts := strings.Split(cleanPath, string(os.PathSeparator))
	var dirs []string
	for _, part := range parts {
		if part != "" && part != "." {
			dirs = append(dirs, part)
		}
	}

	if len(dirs) == 0 {
		return ""
	}

	// æ ¹æ® level è®¡ç®—ç´¢å¼•
	var index int
	if level > 0 {
		// æ­£æ•°ï¼šä»å¤–å‘å†…ï¼ˆ1-basedï¼‰
		index = level - 1
		if index >= len(dirs) {
			// å±‚çº§ä¸å¤Ÿï¼Œå›é€€åˆ°æœ€åä¸€å±‚
			index = len(dirs) - 1
		}
	} else if level < 0 {
		// è´Ÿæ•°ï¼šä»å†…å‘å¤–
		index = len(dirs) + level
		if index < 0 {
			// å±‚çº§ä¸å¤Ÿï¼Œå›é€€åˆ°ç¬¬ä¸€å±‚
			index = 0
		}
	} else {
		// level == 0ï¼Œè¿”å›ç©º
		return ""
	}

	return dirs[index]
}

// downloadDocument ä¸‹è½½å•ä¸ªé£ä¹¦æ–‡æ¡£å¹¶è½¬æ¢ä¸ºMarkdown
// å®ƒå¤„ç†æ–‡æ¡£éªŒè¯ã€å†…å®¹æ£€ç´¢ã€å›¾ç‰‡å¤„ç†å’Œæ–‡ä»¶è¾“å‡º
func downloadDocument(ctx context.Context, client *core.Client, url string, opts *DownloadOpts) error {
	// éªŒè¯URLå¹¶æå–æ–‡æ¡£ç±»å‹å’Œä»¤ç‰Œ
	docType, docToken, err := utils.ValidateDocumentURL(url)
	if err != nil {
		return err
	}
	// ç§»é™¤å†—ä½™çš„ä»¤ç‰Œè¾“å‡º

	// å¯¹äºçŸ¥è¯†åº“é¡µé¢ï¼Œæˆ‘ä»¬éœ€è¦å…ˆæ›´æ–°docTypeå’ŒdocToken
	if docType == "wiki" {
		node, err := client.GetWikiNodeInfo(ctx, docToken)
		if err != nil {
			err = fmt.Errorf("GetWikiNodeInfo err: %v for %v", err, url)
		}
		utils.CheckErr(err)
		docType = node.ObjType
		docToken = node.ObjToken

		// å¦‚æœæä¾›äº†spaceIDï¼Œæ£€æŸ¥è¯¥èŠ‚ç‚¹æ˜¯å¦æœ‰å­èŠ‚ç‚¹
		if opts.spaceID != "" {
			childNodes, err := client.GetChildNodes(ctx, opts.spaceID, node.NodeToken)
			if err == nil && len(childNodes) > 0 {
				fmt.Printf("â­ï¸  è·³è¿‡æœ‰å­èŠ‚ç‚¹çš„æ–‡æ¡£: %s\n", node.Title)
				return nil
			}
		}
	}
	if docType == "docs" {
		return errors.Errorf(
			`ä¸å†æ”¯æŒé£ä¹¦æ–‡æ¡£ã€‚` +
				`è¯·å‚è€ƒReadme/Releaseè·å–v1_supportä¿¡æ¯ã€‚`)
	}

	// å¤„ç†ä¸‹è½½ï¼šå…ˆå¿«é€Ÿè·å–æ–‡æ¡£å…ƒä¿¡æ¯ï¼ˆåŒ…å« RevisionIDï¼‰ï¼Œç”¨äºå‘½ä¸­è·³è¿‡
	meta, err := client.GetDocxDocumentMeta(ctx, docToken)
	utils.CheckErr(err)

	// å¦‚æœå¼€å¯è·³è¿‡é‡å¤ï¼Œå¹¶ä¸”æœ¬åœ°å­˜åœ¨åŒå md æ–‡ä»¶ï¼ŒåŒæ—¶å¯è¯»å–å†å² RevisionIDï¼Œä¸”ä¸€è‡´ï¼Œåˆ™ç›´æ¥è·³è¿‡
	// ä»…åœ¨ä½¿ç”¨æ ‡é¢˜ä½œä¸ºæ–‡ä»¶åæ—¶ï¼Œæ–‡ä»¶åä¾èµ– meta.Titleï¼›å¦åˆ™ç”¨ token
	mdName := fmt.Sprintf("%s.md", docToken)
	if dlConfig.Output.TitleAsFilename {
		mdName = fmt.Sprintf("%s.md", utils.SanitizeFileName(meta.Title))
	}
	outputPath := filepath.Join(opts.outputDir, mdName)

	// æœªå‘½ä¸­å¿«é€Ÿè·³è¿‡ï¼Œæ‹‰å–å—å†…å®¹
	docx, blocks, err := client.GetDocxContent(ctx, docToken)
	utils.CheckErr(err)

	parser := core.NewParser(dlConfig.Output)

	markdown := parser.ParseDocxContent(docx, blocks)

	if !dlConfig.Output.SkipImgDownload && len(parser.ImgTokens) > 0 {
		// å¯¹å›¾ç‰‡ token å»é‡ï¼Œé¿å…é‡å¤ä¸‹è½½
		uniqueTokens := make([]string, 0, len(parser.ImgTokens))
		seen := make(map[string]struct{}, len(parser.ImgTokens))
		for _, t := range parser.ImgTokens {
			if _, ok := seen[t]; ok {
				continue
			}
			seen[t] = struct{}{}
			uniqueTokens = append(uniqueTokens, t)
		}

		// æ£€æŸ¥ PicGo æ˜¯å¦å¯ç”¨
		picgoEnabled := dlConfig.PicGo.Enabled && picgo.IsAvailable()

		// æ§åˆ¶å•æ–‡æ¡£å†…å›¾ç‰‡ä¸‹è½½å¹¶å‘åº¦
		maxImgConcurrency := 16
		type result struct {
			token, link string
			fromCache   bool // æ˜¯å¦ä»ç¼“å­˜è·å–
			needUpload  bool // æ˜¯å¦éœ€è¦ä¸Šä¼ åˆ° PicGo
			err         error
		}
		jobs := make(chan string)
		results := make(chan result, len(uniqueTokens))
		outImgDir := filepath.Join(opts.outputDir, dlConfig.Output.ImageDir)

		worker := func() {
			for token := range jobs {
				// 1. æ£€æŸ¥ PicGo ç¼“å­˜
				if picgoEnabled {
					if cachedURL, ok := picgo.GetCached(token); ok {
						results <- result{token: token, link: cachedURL, fromCache: true, needUpload: false, err: nil}
						continue
					}
				}

				// 2. ä»é£ä¹¦ä¸‹è½½å›¾ç‰‡
				localLink, err := client.DownloadImage(ctx, token, outImgDir)
				if err != nil {
					results <- result{token: token, link: "", fromCache: false, needUpload: false, err: err}
					continue
				}

				// 3. ä¸‹è½½æˆåŠŸï¼Œå¦‚æœå¯ç”¨äº† PicGoï¼Œæ ‡è®°éœ€è¦ä¸Šä¼ 
				if picgoEnabled {
					results <- result{token: token, link: localLink, fromCache: false, needUpload: true, err: nil}
				} else {
					// æœªå¯ç”¨ PicGoï¼Œä½¿ç”¨æœ¬åœ°è·¯å¾„
					results <- result{token: token, link: localLink, fromCache: false, needUpload: false, err: nil}
				}
			}
		}
		for i := 0; i < maxImgConcurrency; i++ {
			go worker()
		}
		for _, token := range uniqueTokens {
			jobs <- token
		}
		close(jobs)

		// æ”¶é›†ç»“æœ
		successCount := 0
		cacheHitCount := 0
		tokenToLink := make(map[string]string, len(uniqueTokens))
		needUploadImages := make(map[string]string) // token -> localLink

		for i := 0; i < len(uniqueTokens); i++ {
			r := <-results
			if r.err != nil {
				fmt.Printf("âš ï¸  å›¾ç‰‡ä¸‹è½½å¤±è´¥: %v\n", r.err)
				continue
			}
			tokenToLink[r.token] = r.link
			successCount++

			if r.fromCache {
				cacheHitCount++
			} else if r.needUpload {
				needUploadImages[r.token] = r.link
			}
		}

		// å¤„ç†éœ€è¦ä¸Šä¼ çš„å›¾ç‰‡
		if successCount > 0 {
			if picgoEnabled && len(needUploadImages) > 0 {
				// æ”¶é›†éœ€è¦ä¸Šä¼ çš„å›¾ç‰‡è·¯å¾„
				localPaths := make([]string, 0, len(needUploadImages))
				tokenByPath := make(map[string]string, len(needUploadImages))
				for token, link := range needUploadImages {
					fullPath := filepath.Join(opts.outputDir, link)
					localPaths = append(localPaths, fullPath)
					tokenByPath[fullPath] = token
				}

				// æ‰¹é‡ä¸Šä¼ åˆ° PicGoï¼ˆå†…éƒ¨å·²å¤„ç†ç¼“å­˜ä¿å­˜ï¼‰
				picgoURLs := picgo.BatchUpload(ctx, localPaths)

				// æ›¿æ¢ tokenToLink ä¸­çš„é“¾æ¥ä¸º PicGo URLï¼Œå¹¶åˆ é™¤å·²ä¸Šä¼ çš„æœ¬åœ°æ–‡ä»¶
				for fullPath, picgoURL := range picgoURLs {
					token := tokenByPath[fullPath]
					tokenToLink[token] = picgoURL

					// ä¸Šä¼ æˆåŠŸååˆ é™¤æœ¬åœ°å›¾ç‰‡
					os.Remove(fullPath)
				}

				// å°è¯•åˆ é™¤ç©ºçš„å›¾ç‰‡ç›®å½•
				imgDir := filepath.Join(opts.outputDir, dlConfig.Output.ImageDir)
				if entries, err := os.ReadDir(imgDir); err == nil && len(entries) == 0 {
					os.Remove(imgDir)
				}
			}

			// æ›¿æ¢ markdown ä¸­çš„ token ä¸ºæœ€ç»ˆé“¾æ¥
			for token, link := range tokenToLink {
				markdown = strings.ReplaceAll(markdown, token, link)
			}

			if dlStats != nil {
				downloaded := len(needUploadImages)
				dlStats.AddImages(len(uniqueTokens), downloaded)
				pathForLog := mdName
				if opts.relDir != "" {
					pathForLog = filepath.Join(opts.relDir, mdName)
				}
				logCollector.Add(DocLog{Path: pathForLog, ImgCache: cacheHitCount, ImgNew: downloaded})
			}
		}
	}

	// Format the markdown document
	engine := lute.New(func(l *lute.Lute) {
		l.RenderOptions.AutoSpace = true
	})
	result := engine.FormatStr("md", markdown)

	// æ„å»º frontmatterï¼ˆMDX/YAMLï¼‰
	// æ ‡é¢˜
	fmTitle := meta.Title
	// è·å–æ—¶é—´å…ƒæ•°æ®
	var fmDate, fmUpdated string
	if createdAt, updatedAt, terr := client.GetDocxTimes(ctx, docToken); terr == nil {
		// å›ºå®šä¸œå…«åŒº +08:00
		loc, _ := time.LoadLocation("Asia/Shanghai")
		if createdAt != nil {
			fmDate = createdAt.In(loc).Format("2006-01-02T15:04:05-07:00")
		}
		if updatedAt != nil {
			fmUpdated = updatedAt.In(loc).Format("2006-01-02T15:04:05-07:00")
		}
	}
	// å…œåº•ï¼šè‹¥æ—¶é—´ç¼ºå¤±ï¼Œä½¿ç”¨å½“å‰æ—¶é—´
	if fmDate == "" || fmUpdated == "" {
		now := time.Now().In(time.FixedZone("CST-8", 8*3600))
		if fmDate == "" {
			fmDate = now.Format("2006-01-02T15:04:05-07:00")
		}
		if fmUpdated == "" {
			fmUpdated = now.Format("2006-01-02T15:04:05-07:00")
		}
	}
	// YAML è½¬ä¹‰æ ‡é¢˜ä¸­çš„å†’å·ç­‰
	escapeYAML := func(s string) string {
		// ç®€å•å¤„ç†ï¼šè‹¥åŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼Œåˆ™ä½¿ç”¨åŒå¼•å·å¹¶è½¬ä¹‰
		special := ":-#{}[],&*?|\"<>=!%@`) \\" // åŒ…å«å¼•å·ã€åæ–œçº¿ä¸å¸¸è§ç‰¹æ®Šå­—ç¬¦
		if strings.ContainsAny(s, special) {
			// è½¬ä¹‰åŒå¼•å·ä¸åæ–œçº¿
			s = strings.ReplaceAll(s, "\\", "\\\\")
			s = strings.ReplaceAll(s, "\"", "\\\"")
			return "\"" + s + "\""
		}
		return s
	}
	var fmBuilder strings.Builder
	fmBuilder.WriteString("---\n")
	fmBuilder.WriteString("title: " + escapeYAML(fmTitle) + "\n")
	fmBuilder.WriteString("date: " + fmDate + "\n")
	fmBuilder.WriteString("updated: " + fmUpdated + "\n")

	// categories: ä½¿ç”¨æä¾›çš„ categoryï¼Œæˆ–å– tags ç¬¬ä¸€ä¸ªï¼Œæˆ–ä½¿ç”¨é»˜è®¤åˆ†ç±»
	fmCategory := opts.category
	if fmCategory == "" && len(opts.tags) > 0 {
		fmCategory = opts.tags[0] // ä½¿ç”¨ç¬¬ä¸€ä¸ª tag ä½œä¸º category
	}
	if fmCategory == "" {
		fmCategory = "æœªåˆ†ç±»" // é»˜è®¤åˆ†ç±»
	}
	fmBuilder.WriteString("categories: " + escapeYAML(fmCategory) + "\n")

	// tags: è¾“å‡ºæ ‡ç­¾åˆ—è¡¨
	if len(opts.tags) > 0 {
		fmBuilder.WriteString("tags:\n")
		for _, tag := range opts.tags {
			if strings.TrimSpace(tag) == "" {
				continue
			}
			fmBuilder.WriteString("  - " + escapeYAML(tag) + "\n")
		}
	}
	// id: ä½¿ç”¨ docToken ä½œä¸ºå”¯ä¸€æ ‡è¯†
	fmBuilder.WriteString("id: " + escapeYAML(docToken) + "\n")
	fmBuilder.WriteString("---\n\n")

	// åˆå¹¶ frontmatter ä¸æ­£æ–‡
	result = fmBuilder.String() + result

	// å¤„ç†è¾“å‡ºç›®å½•å’Œåç§°
	if _, err := os.Stat(opts.outputDir); os.IsNotExist(err) {
		if err := os.MkdirAll(opts.outputDir, 0o755); err != nil {
			return err
		}
	}

	if opts.dumpJSON {
		jsonName := fmt.Sprintf("%s.json", docToken)
		jsonOutputPath := filepath.Join(opts.outputDir, jsonName)
		data := struct {
			Document *lark.DocxDocument `json:"document"`
			Blocks   []*lark.DocxBlock  `json:"blocks"`
		}{
			Document: docx,
			Blocks:   blocks,
		}
		pdata := utils.PrettyPrint(data)

		// æ£€æŸ¥JSONæ–‡ä»¶æ˜¯å¦éœ€è¦è·³è¿‡
		if !opts.forceDownload && shouldSkipFile(jsonOutputPath, pdata, opts.skipDuplicate) {
			fmt.Printf("â­ï¸  è·³è¿‡é‡å¤JSON: %s\n", jsonName)
		} else {
			if err = os.WriteFile(jsonOutputPath, []byte(pdata), 0o644); err != nil {
				return err
			}
			fmt.Printf("ğŸ“„ JSONå“åº”å·²è½¬å‚¨åˆ° %s\n", jsonOutputPath)
		}
	}

	// å†™å…¥markdownæ–‡ä»¶

	// æ£€æŸ¥æ˜¯å¦éœ€è¦è·³è¿‡é‡å¤æ–‡ä»¶
	if !opts.forceDownload && shouldSkipFile(outputPath, result, opts.skipDuplicate) {
		// é™é»˜è·³è¿‡ï¼Œä¸è¾“å‡ºæ—¥å¿—
		return nil
	}

	if err = os.WriteFile(outputPath, []byte(result), 0o644); err != nil {
		return err
	}
	// é™é»˜å®Œæˆï¼Œä¸è¾“å‡ºæ—¥å¿—ï¼ˆåœ¨æœ€åç»Ÿè®¡è¾“å‡ºï¼‰
	if dlStats != nil {
		dlStats.AddDocNew()
		// è®°å½•æ–‡æ¡£æ–°å¢æ—¥å¿—ï¼ˆå›¾ç‰‡ç»Ÿè®¡åœ¨å‰é¢ AddImages å·²åšç´¯åŠ ï¼‰
		pathForLog := mdName
		if opts.relDir != "" {
			pathForLog = filepath.Join(opts.relDir, mdName)
		}
		logCollector.Add(DocLog{Path: pathForLog, DocNew: true})
	}

	return nil
}

// downloadDocuments ä¸‹è½½æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡æ¡£
func downloadDocuments(ctx context.Context, client *core.Client, url string, opts *DownloadOpts) error {
	// éªŒè¯è¦ä¸‹è½½çš„URL
	folderToken, err := utils.ValidateFolderURL(url)
	if err != nil {
		return err
	}
	// ç§»é™¤å†—ä½™çš„ä»¤ç‰Œè¾“å‡º

	// é”™è¯¯é€šé“å’Œç­‰å¾…ç»„
	errChan := make(chan error)
	wg := sync.WaitGroup{}

	// é€’å½’éå†æ–‡ä»¶å¤¹å¹¶ä¸‹è½½æ–‡æ¡£
	var processFolder func(ctx context.Context, folderPath, folderToken string) error
	processFolder = func(ctx context.Context, folderPath, folderToken string) error {
		files, err := client.GetDriveFolderFileList(ctx, nil, &folderToken)
		if err != nil {
			return err
		}
		localOpts := DownloadOpts{
			outputDir:     folderPath,
			dumpJSON:      opts.dumpJSON,
			skipDuplicate: opts.skipDuplicate,
			forceDownload: opts.forceDownload,
			spaceID:       opts.spaceID,
			nodeToken:     opts.nodeToken,
		}
		for _, file := range files {
			switch file.Type {
			case "folder":
				_folderPath := filepath.Join(folderPath, file.Name)
				if err := processFolder(ctx, _folderPath, file.Token); err != nil {
					return err
				}
			case "docx":
				// å¹¶å‘ä¸‹è½½æ–‡æ¡£
				wg.Add(1)
				go func(_url string) {
					if err := downloadDocument(ctx, client, _url, &localOpts); err != nil {
						errChan <- err
					}
					wg.Done()
				}(file.URL)
			}
		}
		return nil
	}
	if err := processFolder(ctx, opts.outputDir, folderToken); err != nil {
		return err
	}

	// Wait for all the downloads to finish
	go func() {
		wg.Wait()
		close(errChan)
	}()
	for err := range errChan {
		return err
	}
	return nil
}

// downloadWiki ä¸‹è½½çŸ¥è¯†åº“ä¸­çš„æ‰€æœ‰æ–‡æ¡£
func downloadWiki(ctx context.Context, client *core.Client, url string, opts *DownloadOpts) error {
	prefixURL, spaceID, err := utils.ValidateWikiURL(url)
	if err != nil {
		return err
	}

	folderPath, err := client.GetWikiName(ctx, spaceID)
	if err != nil {
		return err
	}
	if folderPath == "" {
		return fmt.Errorf("failed to GetWikiName")
	}

	errChan := make(chan error)

	var maxConcurrency = 10 // è®¾ç½®æœ€å¤§å¹¶å‘çº§åˆ«
	wg := sync.WaitGroup{}
	semaphore := make(chan struct{}, maxConcurrency) // åˆ›å»ºå…·æœ‰æœ€å¤§å¹¶å‘çº§åˆ«çš„ä¿¡å·é‡

	var downloadWikiNode func(ctx context.Context,
		client *core.Client,
		spaceID string,
		parentPath string,
		parentNodeToken *string) error

	downloadWikiNode = func(ctx context.Context,
		client *core.Client,
		spaceID string,
		folderPath string,
		parentNodeToken *string) error {
		nodes, err := client.GetWikiNodeList(ctx, spaceID, parentNodeToken)
		if err != nil {
			return err
		}
		for _, n := range nodes {
			if n.HasChild {
				_folderPath := filepath.Join(folderPath, n.Title)
				if err := downloadWikiNode(ctx, client,
					spaceID, _folderPath, &n.NodeToken); err != nil {
					return err
				}
			}
			if n.ObjType == "docx" {
				wikiOpts := DownloadOpts{
					outputDir:     folderPath,
					dumpJSON:      opts.dumpJSON,
					skipDuplicate: opts.skipDuplicate,
					forceDownload: opts.forceDownload,
					spaceID:       spaceID,
					nodeToken:     n.NodeToken,
				}
				wg.Add(1)
				semaphore <- struct{}{}
				go func(_url string) {
					if err := downloadDocument(ctx, client, _url, &wikiOpts); err != nil {
						errChan <- err
					}
					wg.Done()
					<-semaphore
				}(prefixURL + "/wiki/" + n.NodeToken)
			}
		}
		return nil
	}

	if err = downloadWikiNode(ctx, client, spaceID, folderPath, nil); err != nil {
		return err
	}

	// Wait for all the downloads to finish
	go func() {
		wg.Wait()
		close(errChan)
	}()
	for err := range errChan {
		return err
	}
	return nil
}

// downloadWikiChildren ä¸‹è½½æŒ‡å®šçŸ¥è¯†åº“æ–‡æ¡£ä¸‹çš„æ‰€æœ‰å­æ–‡æ¡£
func downloadWikiChildren(ctx context.Context, client *core.Client, url string, opts *DownloadOpts) error {
	startTime := time.Now()

	// ä¼˜å…ˆä½¿ç”¨é…ç½®ä¸­çš„spaceIDï¼Œç„¶åä½¿ç”¨ç¯å¢ƒå˜é‡
	spaceID := opts.spaceID
	if spaceID == "" {
		spaceID = os.Getenv("FEISHU_SPACE_ID")
	}
	var prefixURL string

	if spaceID == "" {
		// å°è¯•ä»URLè§£æspaceIDï¼ˆå¦‚æœæ˜¯çŸ¥è¯†åº“è®¾ç½®é¡µé¢URLï¼‰
		var parsedSpaceID string
		var err error
		prefixURL, parsedSpaceID, err = utils.ValidateWikiURL(url)
		if err == nil {
			spaceID = parsedSpaceID
		}
	}

	if spaceID == "" {
		return fmt.Errorf("æ— æ³•è·å–çŸ¥è¯†åº“spaceIDã€‚è¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼æä¾›:\n" +
			"  1. ç¯å¢ƒå˜é‡: FEISHU_SPACE_ID (åœ¨ .env æ–‡ä»¶ä¸­é…ç½®)\n" +
			"  2. ä½¿ç”¨çŸ¥è¯†åº“è®¾ç½®é¡µé¢URL\n\n" +
			"æç¤º: è¿è¡Œ 'feishu2md init' åˆ›å»ºé…ç½®æ–‡ä»¶æ¨¡æ¿")
	}

	// å¦‚æœè¿˜æ²¡æœ‰è·å–URLå‰ç¼€ï¼Œåˆ™ä»URLä¸­æå–
	if prefixURL == "" {
		if urlParts := strings.Split(url, "/wiki/"); len(urlParts) >= 2 {
			prefixURL = urlParts[0]
		}
	}

	// ä»URLä¸­æå–nodeToken
	docType, nodeToken, err := utils.ValidateDocumentURL(url)
	if err != nil {
		return err
	}

	// å¦‚æœæ˜¯wikiç±»å‹ï¼Œéœ€è¦è·å–å®é™…çš„æ–‡æ¡£ä¿¡æ¯
	if docType == "wiki" {
		node, err := client.GetWikiNodeInfo(ctx, nodeToken)
		if err != nil {
			return fmt.Errorf("GetWikiNodeInfo err: %v for %v", err, url)
		}
		nodeToken = node.NodeToken
	}

	fmt.Printf("ğŸ” æ­£åœ¨è·å–å­æ–‡æ¡£...\n")

	// å¯é€‰ï¼šå…ˆæ¸…ç©ºè¾“å‡ºç›®å½•ï¼Œå†æŒ‰æœ€æ–°æ ‘ç”Ÿæˆï¼Œé¿å…é‡å‘½å/åˆ é™¤å¯¼è‡´çš„æ—§æ–‡ä»¶æ®‹ç•™
	if opts.cleanOutput && opts.outputDir != "" {
		if _, err := os.Stat(opts.outputDir); err == nil {
			if err := os.RemoveAll(opts.outputDir); err != nil {
				return fmt.Errorf("æ¸…ç©ºè¾“å‡ºç›®å½•å¤±è´¥: %w", err)
			}
			fmt.Printf("ğŸ§¹ å·²æ¸…ç©ºè¾“å‡ºç›®å½•: %s\n", opts.outputDir)
		}
	}
	if err := os.MkdirAll(opts.outputDir, 0o755); err != nil {
		return fmt.Errorf("åˆ›å»ºè¾“å‡ºç›®å½•å¤±è´¥: %w", err)
	}

	// è·å–æ‰€æœ‰å­èŠ‚ç‚¹
	allNodes, err := client.GetAllChildNodes(ctx, spaceID, nodeToken)
	if err != nil {
		return fmt.Errorf("è·å–å­èŠ‚ç‚¹å¤±è´¥: %v", err)
	}

	if len(allNodes) == 0 {
		fmt.Println("ğŸ“­ æœªæ‰¾åˆ°ä»»ä½•å­æ–‡æ¡£")
		return nil
	}

	fmt.Printf("ğŸ“š æ‰¾åˆ° %d ä¸ªå­æ–‡æ¡£\n", len(allNodes))
	dlStats = &DownloadStats{}
	dlStats.SetTotalDocs(len(allNodes))

	// åˆ›å»ºç›®å½•ç»“æ„æ˜ å°„ï¼šnodeToken -> ç›¸å¯¹è·¯å¾„
	pathMap := make(map[string]string)

	// é¦–å…ˆä¸ºæ ¹èŠ‚ç‚¹å»ºç«‹è·¯å¾„
	pathMap[nodeToken] = "."

	// é€’å½’æ„å»ºè·¯å¾„æ˜ å°„
	var buildPaths func(parentToken, parentPath string)
	buildPaths = func(parentToken, parentPath string) {
		for _, node := range allNodes {
			if node.ParentToken == parentToken {
				// æ„å»ºå½“å‰èŠ‚ç‚¹çš„è·¯å¾„
				nodePath := filepath.Join(parentPath, utils.SanitizeFileName(node.Name))
				pathMap[node.NodeToken] = nodePath

				// å¦‚æœæœ‰å­èŠ‚ç‚¹ï¼Œé€’å½’å¤„ç†
				if node.HasChild {
					buildPaths(node.NodeToken, nodePath)
				}
			}
		}
	}

	buildPaths(nodeToken, ".")

	// å¹¶å‘ä¸‹è½½æ§åˆ¶
	// æé«˜å¹¶å‘åº¦åˆ°20ï¼šé™æµå™¨(100æ¬¡/åˆ†é’Ÿ+5æ¬¡/ç§’)ä¼šè‡ªåŠ¨æ§åˆ¶APIè°ƒç”¨é€Ÿç‡
	// 20ä¸ªå¹¶å‘æ–‡æ¡£ Ã— å¹³å‡3æ¬¡APIè°ƒç”¨/æ–‡æ¡£ = çº¦60æ¬¡å¹¶å‘APIè°ƒç”¨
	// é™æµå™¨ä¼šå°†å…¶å¹³æ»‘åˆ°å®‰å…¨èŒƒå›´å†…
	var maxConcurrency = 20
	errChan := make(chan error, len(allNodes))
	wg := sync.WaitGroup{}
	semaphore := make(chan struct{}, maxConcurrency)

	// ä¸‹è½½æ‰€æœ‰æ–‡æ¡£ç±»å‹çš„èŠ‚ç‚¹
	for _, node := range allNodes {
		if node.Type == "docx" {
			wg.Add(1)
			semaphore <- struct{}{}

			go func(n *core.Document) {
				defer func() {
					wg.Done()
					<-semaphore
				}()

				// ç¡®å®šæ–‡æ¡£çš„è¾“å‡ºç›®å½•
				nodePath := pathMap[n.ParentToken]
				if nodePath == "" {
					nodePath = "." // é»˜è®¤åˆ°å½“å‰ç›®å½•
				}

				fullOutputDir := filepath.Join(opts.outputDir, nodePath)

				// åˆ›å»ºè¾“å‡ºç›®å½•
				if err := os.MkdirAll(fullOutputDir, 0o755); err != nil {
					errChan <- fmt.Errorf("åˆ›å»ºç›®å½•å¤±è´¥ %s: %v", fullOutputDir, err)
					return
				}

				// æ„å»ºæ–‡æ¡£URLå¹¶ä¸‹è½½
				docURL := prefixURL + "/wiki/" + n.NodeToken
				localOpts := DownloadOpts{
					outputDir:     fullOutputDir,
					dumpJSON:      opts.dumpJSON,
					skipDuplicate: opts.skipDuplicate,
					forceDownload: opts.forceDownload,
					spaceID:       spaceID,
					nodeToken:     n.NodeToken,
					relDir:        nodePath,
					categoryLevel: opts.categoryLevel,
					tags:          deriveTagsFromPath(nodePath),
					category:      deriveCategoryFromPath(nodePath, opts.categoryLevel),
				}

				// ç§»é™¤å†—ä½™çš„ä¸‹è½½è·¯å¾„è¾“å‡º
				if err := downloadDocument(ctx, client, docURL, &localOpts); err != nil {
					errChan <- fmt.Errorf("ä¸‹è½½æ–‡æ¡£å¤±è´¥ %s: %v", n.Name, err)
				}
			}(node)
		}
	}

	// ç­‰å¾…æ‰€æœ‰ä¸‹è½½å®Œæˆ
	go func() {
		wg.Wait()
		close(errChan)
	}()

	// æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
	for err := range errChan {
		if err != nil {
			return err
		}
	}

	// è®¡ç®—æ€»è€—æ—¶
	elapsed := time.Since(startTime)

	// ç»Ÿè®¡æ±‡æ€»è¾“å‡ºï¼ˆæ•´æ´æ ¼å¼ï¼‰
	fmt.Println()
	fmt.Println("ğŸ“¦ å¤„ç†ç»“æœï¼š")
	for _, l := range logCollector.SortedByPath() {
		status := "ç¼“å­˜"
		if l.DocNew {
			status = "æ–°å¢"
		} else if l.Skipped {
			status = "è·³è¿‡"
		}
		if l.Reason != "" {
			status += " (" + l.Reason + ")"
		}
		fmt.Printf("- %s  [%s]", l.Path, status)
		if l.ImgCache > 0 || l.ImgNew > 0 {
			fmt.Printf("  | å›¾ç‰‡: +%d / å‘½ä¸­%d", l.ImgNew, l.ImgCache)
		}
		fmt.Println()
	}

	// æ±‡æ€»
	totalDocs, docsNew, totalImages, imagesNew := dlStats.Snapshot()
	changes := docsNew + imagesNew
	if changes == 0 {
		fmt.Printf("ğŸ‰ å®Œæˆï¼å…± %d ä¸ªæ–‡æ¡£ã€%d å¼ å›¾ç‰‡ï¼Œå…¨éƒ¨å·²ç¼“å­˜ã€æ— æ›´æ–°ã€‚è€—æ—¶: %.2fs\n", totalDocs, totalImages, elapsed.Seconds())
	} else {
		fmt.Printf("ğŸ‰ å®Œæˆï¼å…± %d ä¸ªæ–‡æ¡£ã€%d å¼ å›¾ç‰‡ï¼Œå…¶ä¸­æ–°å¢æ–‡æ¡£ %dã€æ–°å¢å›¾ç‰‡ %dï¼Œå…± %d å¤„å˜æ›´ã€‚è€—æ—¶: %.2fs\n", totalDocs, totalImages, docsNew, imagesNew, changes, elapsed.Seconds())
	}
	return nil
}

// createCommonOpts ä»CLIä¸Šä¸‹æ–‡åˆ›å»ºé€šç”¨çš„ä¸‹è½½é€‰é¡¹
func createCommonOpts(cliCtx *cli.Context) (*DownloadOpts, *core.Config, error) {
	// åŠ è½½é…ç½®æ–‡ä»¶ï¼ˆå¦‚æœæŒ‡å®šï¼‰
	configPath := cliCtx.String("config")
	if configPath != "" {
		if err := core.LoadEnvFileIfExists(configPath); err != nil {
			return nil, nil, fmt.Errorf("åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: %w", err)
		}
	}

	// æå–CLIæ ‡å¿—
	spaceId := os.Getenv("FEISHU_SPACE_ID")
	titleAsFilename := cliCtx.Bool("title-name")
	useHTML := cliCtx.Bool("html")
	skipImages := cliCtx.Bool("no-img")
	noBodyTitle := cliCtx.Bool("no-body-title")
	skipDuplicate := cliCtx.Bool("skip-same")
	forceDownload := cliCtx.Bool("force")
	dumpJSON := cliCtx.Bool("json")
	categoryLevel := cliCtx.Int("category-level")

	// åŠ è½½é…ç½®
	config, err := core.LoadConfig("", "")
	if err != nil {
		return nil, nil, err
	}

	// éªŒè¯å‡­æ®
	if config.Feishu.AppId == "" || config.Feishu.AppSecret == "" {
		return nil, nil, cli.Exit("éœ€è¦åº”ç”¨IDå’Œåº”ç”¨å¯†é’¥ã€‚è¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¾ç½®:\n"+
			"  1. ç¯å¢ƒå˜é‡: FEISHU_APP_ID å’Œ FEISHU_APP_SECRET\n"+
			"  2. é…ç½®æ–‡ä»¶: ä½¿ç”¨ --config æŒ‡å®šé…ç½®æ–‡ä»¶è·¯å¾„\n"+
			"  3. è¿è¡Œ 'feishu2md init' åˆ›å»ºé…ç½®æ–‡ä»¶æ¨¡æ¿", 1)
	}

	// ä½¿ç”¨CLIæ ‡å¿—è¦†ç›–é…ç½®
	config.Output.TitleAsFilename = titleAsFilename
	config.Output.UseHTMLTags = useHTML
	config.Output.SkipImgDownload = skipImages
	config.Output.NoBodyTitle = noBodyTitle

	// åˆ›å»ºä¸‹è½½é€‰é¡¹
	opts := &DownloadOpts{
		outputDir:     config.Output.OutputDir,
		dumpJSON:      dumpJSON,
		skipDuplicate: skipDuplicate,
		forceDownload: forceDownload,
		spaceID:       spaceId,
		nodeToken:     "",
		categoryLevel: categoryLevel,
	}

	return opts, config, nil
}

// handleDocumentDownload å¤„ç†å•ä¸ªæ–‡æ¡£ä¸‹è½½
func handleDocumentDownload(cliCtx *cli.Context, url string) error {
	opts, config, err := createCommonOpts(cliCtx)
	if err != nil {
		return err
	}

	dlConfig = *config
	client := core.NewClient(config.Feishu.AppId, config.Feishu.AppSecret)
	ctx := context.Background()

	return downloadDocument(ctx, client, url, opts)
}

// handleFolderDownload å¤„ç†æ–‡ä»¶å¤¹æ‰¹é‡ä¸‹è½½
func handleFolderDownload(cliCtx *cli.Context, url string) error {
	opts, config, err := createCommonOpts(cliCtx)
	if err != nil {
		return err
	}

	dlConfig = *config
	client := core.NewClient(config.Feishu.AppId, config.Feishu.AppSecret)
	ctx := context.Background()

	return downloadDocuments(ctx, client, url, opts)
}

// handleWikiDownload å¤„ç†çŸ¥è¯†åº“å®Œæ•´ä¸‹è½½
func handleWikiDownload(cliCtx *cli.Context, url string) error {
	opts, config, err := createCommonOpts(cliCtx)
	if err != nil {
		return err
	}

	dlConfig = *config
	client := core.NewClient(config.Feishu.AppId, config.Feishu.AppSecret)
	ctx := context.Background()

	return downloadWiki(ctx, client, url, opts)
}

// handleWikiTreeCommand å¤„ç†çŸ¥è¯†åº“å­æ–‡æ¡£ä¸‹è½½å‘½ä»¤
func handleWikiTreeCommand(cliCtx *cli.Context) error {
	// å…ˆåŠ è½½é…ç½®æ–‡ä»¶
	configPath := cliCtx.String("config")
	if configPath != "" {
		if err := core.LoadEnvFileIfExists(configPath); err != nil {
			return fmt.Errorf("åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: %w", err)
		}
	}

	// è·å– URLï¼šä¼˜å…ˆä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ï¼Œå…¶æ¬¡ä½¿ç”¨ç¯å¢ƒå˜é‡
	var url string
	if cliCtx.NArg() > 0 {
		url = cliCtx.Args().First()
	} else {
		url = os.Getenv("FEISHU_FOLDER_TOKEN")
	}

	if url == "" {
		return cli.Exit("é”™è¯¯: è¯·æŒ‡å®šçŸ¥è¯†åº“æ–‡æ¡£URL\n\n"+
			"æ–¹å¼ä¸€: feishu2md wiki-tree <URL>\n"+
			"æ–¹å¼äºŒ: åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½® FEISHU_FOLDER_TOKEN\n\n"+
			"æç¤º: è¿˜éœ€è¦åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½® FEISHU_SPACE_ID", 1)
	}

	return handleWikiTreeDownload(cliCtx, url)
}

// handleWikiTreeDownload å¤„ç†çŸ¥è¯†åº“å­æ–‡æ¡£ä¸‹è½½
func handleWikiTreeDownload(cliCtx *cli.Context, url string) error {
	opts, config, err := createCommonOpts(cliCtx)
	if err != nil {
		return err
	}
	opts.cleanOutput = cliCtx.Bool("clean-output")

	dlConfig = *config
	client := core.NewClient(config.Feishu.AppId, config.Feishu.AppSecret)
	ctx := context.Background()

	return downloadWikiChildren(ctx, client, url, opts)
}

// handleLegacyDownload å¤„ç†é—ç•™çš„æ™ºèƒ½ä¸‹è½½å‘½ä»¤ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
func handleLegacyDownload(cliCtx *cli.Context, url string) error {
	fmt.Println("âš ï¸  ä½¿ç”¨äº†å·²åºŸå¼ƒçš„å‘½ä»¤ï¼Œå»ºè®®ä½¿ç”¨å…·ä½“çš„å­å‘½ä»¤:")
	fmt.Println("  - feishu2md document <url>  # ä¸‹è½½å•ä¸ªæ–‡æ¡£")
	fmt.Println("  - feishu2md folder <url>    # ä¸‹è½½æ–‡ä»¶å¤¹")
	fmt.Println("  - feishu2md wiki <url>      # ä¸‹è½½çŸ¥è¯†åº“")
	fmt.Println("  - feishu2md wiki-tree <url> # ä¸‹è½½å­æ–‡æ¡£")
	fmt.Println()

	// è‡ªåŠ¨æ£€æµ‹URLç±»å‹å¹¶ä½¿ç”¨ç›¸åº”çš„å¤„ç†å‡½æ•°
	if strings.Contains(url, "/drive/folder/") {
		return handleFolderDownload(cliCtx, url)
	}
	if strings.Contains(url, "/wiki/space/") {
		return handleWikiDownload(cliCtx, url)
	}
	if strings.Contains(url, "/wiki/") {
		// éœ€è¦æ£€æŸ¥æ˜¯å¦æœ‰spaceæ¥å†³å®šæ˜¯wiki-treeè¿˜æ˜¯å•æ–‡æ¡£
		if cliCtx.String("space") != "" {
			return handleWikiTreeDownload(cliCtx, url)
		}
	}

	// é»˜è®¤ä½œä¸ºå•æ–‡æ¡£å¤„ç†
	return handleDocumentDownload(cliCtx, url)
}

// handleDownloadCommand æ˜¯é—ç•™çš„ä¸»è¦å¤„ç†ç¨‹åºï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
func handleDownloadCommand(cliCtx *cli.Context, url string) error {
	return handleLegacyDownload(cliCtx, url)
}
